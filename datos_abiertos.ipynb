{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "def read_csv_with_pyspark(filename, folder='data'):\n",
    "    spark = SparkSession.builder \\\n",
    "        .appName(\"Read CSV with PySpark\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "    file_path = os.path.join(folder, filename)\n",
    "    df = spark.read.csv(file_path, header=True, inferSchema=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------+--------+-----------+----------------------------+----------------------+---------------------+--------------------------+--------------------+--------------+-------------+--------------+\n",
      "|No.|Fecha de Radicacion|Radicado|       Caso|Falta que origina la sancion|Resolucion de Apertura|Resolucion de Sancion|Tipo de Persona Sancionada|Personas Sancionadas|Identificacion|Multa Inicial|Año Radicacion|\n",
      "+---+-------------------+--------+-----------+----------------------------+----------------------+---------------------+--------------------------+--------------------+--------------+-------------+--------------+\n",
      "|  1|2011-06-07 00:00:00|11-71590|VIGILANCIA |        Infringir el artí...|  Resolución de Ape...| Resolución de San...|        Personas Jurídicas|GUARDIANES COMPAÑ...|     860520097| 8.59440305E9|          2011|\n",
      "|  1|2011-06-07 00:00:00|11-71590|VIGILANCIA |        Infringir el artí...|  Resolución de Ape...| Resolución de San...|        Personas Jurídicas|EXPERTOS SEGURIDA...|     800010866| 3.85088274E9|          2011|\n",
      "|  1|2011-06-07 00:00:00|11-71590|VIGILANCIA |        Infringir el artí...|  Resolución de Ape...| Resolución de San...|        Personas Jurídicas|    COBASEC LIMITADA|     891801317|4.651305685E9|          2011|\n",
      "|  1|2011-06-07 00:00:00|11-71590|VIGILANCIA |        Infringir el artí...|  Resolución de Ape...| Resolución de San...|        Personas Jurídicas|COOPERATIVA DE VI...|     830101476|7.026754425E9|          2011|\n",
      "|  1|2011-06-07 00:00:00|11-71590|VIGILANCIA |        Infringir el artí...|  Resolución de Ape...| Resolución de San...|        Personas Jurídicas|CENTINEL DE SEGUR...|     820001482| 3.13529725E8|          2011|\n",
      "+---+-------------------+--------+-----------+----------------------------+----------------------+---------------------+--------------------------+--------------------+--------------+-------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filename = 'colusiones_en_contratacion_SIC.csv'\n",
    "df = read_csv_with_pyspark(filename)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, count, when, isnan, isnull, min, max, mean, stddev\n",
    "from pyspark.sql.types import DoubleType, FloatType, IntegerType, LongType, ShortType, TimestampType\n",
    "\n",
    "def analyze_data_quality(filename, folder='data'):\n",
    "    spark = SparkSession.builder \\\n",
    "        .appName(\"Analyze Data Quality with PySpark\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "    file_path = os.path.join(folder, filename)\n",
    "    df = spark.read.csv(file_path, header=True, inferSchema=True)\n",
    "\n",
    "    # Cuenta de registros\n",
    "    record_count = df.count()\n",
    "    print(f\"Total de registros: {record_count}\")\n",
    "\n",
    "    # Cuenta de registros nulos y duplicados\n",
    "    null_count = df.select([count(when(isnull(c), c)).alias(c) for c in df.columns]).collect()\n",
    "    duplicate_count = df.count() - df.dropDuplicates().count()\n",
    "\n",
    "    print(\"\\nConteo de registros nulos por columna:\")\n",
    "    for col_name, nulls in zip(df.columns, null_count[0]):\n",
    "        print(f\"{col_name}: {nulls}\")\n",
    "\n",
    "    print(f\"\\nConteo de registros duplicados: {duplicate_count}\")\n",
    "\n",
    "    # Estadísticas descriptivas (mínimo, máximo, promedio, desviación estándar) para columnas numéricas\n",
    "    numeric_columns = [col_name for col_name, dtype in df.dtypes if dtype in (\"double\", \"float\", \"int\", \"bigint\", \"smallint\")]\n",
    "    summary_stats = df.select(numeric_columns).summary(\"min\", \"max\", \"mean\", \"stddev\").collect()\n",
    "\n",
    "    print(\"\\nEstadísticas descriptivas para columnas numéricas:\")\n",
    "    for stat in summary_stats:\n",
    "        print(f\"{stat['summary']}:\")\n",
    "\n",
    "        for col_name in numeric_columns:\n",
    "            print(f\"  {col_name}: {stat[col_name]}\")\n",
    "\n",
    "    # Identificación de valores atípicos (basado en el rango intercuartil)\n",
    "    for col_name in numeric_columns:\n",
    "        q1, q3 = df.approxQuantile(col_name, [0.25, 0.75], 0.01)\n",
    "        iqr = q3 - q1\n",
    "        lower_bound = q1 - 1.5 * iqr\n",
    "        upper_bound = q3 + 1.5 * iqr\n",
    "\n",
    "        outliers = df.filter((col(col_name) < lower_bound) | (col(col_name) > upper_bound)).count()\n",
    "\n",
    "        print(f\"\\nValores atípicos en la columna {col_name}: {outliers}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de registros: 1444\n",
      "\n",
      "Conteo de registros nulos por columna:\n",
      "nombre_entidad: 0\n",
      "nit_entidad: 0\n",
      "nivel: 0\n",
      "orden: 0\n",
      "numero_de_resolucion: 0\n",
      "documento_contratista: 0\n",
      "nombre_contratista: 0\n",
      "numero_de_contrato: 0\n",
      "valor_sancion: 0\n",
      "fecha_de_publicacion: 0\n",
      "ruta_de_proceso: 0\n",
      "cod_depto: 11\n",
      "cod_mpio: 11\n",
      "dpto: 0\n",
      "nom_mpio: 0\n",
      "\n",
      "Conteo de registros duplicados: 0\n",
      "\n",
      "Estadísticas descriptivas para columnas numéricas:\n",
      "min:\n",
      "max:\n",
      "mean:\n",
      "stddev:\n"
     ]
    }
   ],
   "source": [
    "analyze_data_quality('multas_SECOP.csv', folder='data')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
